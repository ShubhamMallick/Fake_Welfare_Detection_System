{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c965f32d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dee30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse previous LLM setup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ea420",
   "metadata": {},
   "source": [
    "### Load API key & LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5721e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE = os.getenv(\"OPENAI_API_BASE\", \"https://openrouter.ai/api/v1\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-20b:free\",\n",
    "    temperature=0,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=OPENAI_API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a6dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_risk_score(case_data):\n",
    "    \"\"\"Calculate risk score based on suspicious patterns\"\"\"\n",
    "    risk_score = (\n",
    "        case_data.get('bank_shared_count', 0) * 0.4 +\n",
    "        case_data.get('phone_shared_count', 0) * 0.3 +\n",
    "        case_data.get('registrations_per_aadhaar', 0) * 0.2 +\n",
    "        case_data.get('agent_cluster_size', 0) * 0.1\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'risk_score': min(risk_score, 10),\n",
    "        'risk_level': 'High' if risk_score > 7 else 'Medium' if risk_score > 4 else 'Low',\n",
    "        'factors': [\n",
    "            f\"Bank shared count: {case_data.get('bank_shared_count', 0)}\",\n",
    "            f\"Phone shared count: {case_data.get('phone_shared_count', 0)}\",\n",
    "            f\"Registrations per Aadhaar: {case_data.get('registrations_per_aadhaar', 0)}\"\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842144d9",
   "metadata": {},
   "source": [
    "### Audit summary prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55f9ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_27744\\476703227.py:29: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  audit_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "audit_prompt = PromptTemplate(\n",
    "    input_variables=[\"case_data\", \"risk_data\", \"explanation\"],\n",
    "    template=\"\"\"\n",
    "You are a senior government welfare fraud auditor.\n",
    "\n",
    "Generate an official audit summary for the following suspicious beneficiary case.\n",
    "\n",
    "CASE DATA:\n",
    "{case_data}\n",
    "\n",
    "RISK ANALYSIS:\n",
    "{risk_data}\n",
    "\n",
    "AI EXPLANATION:\n",
    "{explanation}\n",
    "\n",
    "Your report must include:\n",
    "\n",
    "1. Case Overview\n",
    "2. Key Fraud Indicators\n",
    "3. Risk Score Interpretation\n",
    "4. Evidence Summary\n",
    "5. Recommended Government Action\n",
    "\n",
    "Write in clear, formal, audit-ready language.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "audit_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=audit_prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audit_summary(case_data, risk_data, explanation):\n",
    "    \"\"\"Generate audit summary using LLM\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a senior government welfare fraud auditor.\n",
    "\n",
    "Generate an official audit summary for the following suspicious beneficiary case.\n",
    "\n",
    "CASE DATA:\n",
    "{case_data}\n",
    "\n",
    "RISK ANALYSIS:\n",
    "{risk_data}\n",
    "\n",
    "AI EXPLANATION:\n",
    "{explanation}\n",
    "\n",
    "Your report must include:\n",
    "\n",
    "1. Case Overview\n",
    "2. Key Fraud Indicators\n",
    "3. Risk Score Interpretation\n",
    "4. Evidence Summary\n",
    "5. Recommended Government Action\n",
    "\n",
    "Write in clear, formal, audit-ready language.\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating audit summary: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11356033",
   "metadata": {},
   "source": [
    "### Run full pipeline (Explanation â†’ Risk â†’ Audit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbc7066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§¾ FINAL AUDIT REPORT\n",
      "\n",
      "Error generating audit summary: name 'client' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Example suspicious case\n",
    "suspicious_case = {\n",
    "    \"aadhaar_like_id\": \"4587 9214 6632\",\n",
    "    \"phone_number\": \"9876543210\",\n",
    "    \"bank_account\": \"123456789012\",\n",
    "    \"registrations_per_aadhaar\": 3,\n",
    "    \"bank_shared_count\": 5,\n",
    "    \"phone_shared_count\": 4,\n",
    "    \"agent_cluster_size\": 18,\n",
    "    \"annual_income\": \"â‚¹85,000\",\n",
    "    \"district\": \"Bhopal\"\n",
    "}\n",
    "\n",
    "# --- Step 1: Explanation (from previous LangGraph result) ---\n",
    "explanation_text = \"Mock explanation: This beneficiary shows multiple red flags including high shared banking relationships and multiple registrations per Aadhaar ID, indicating potential fraudulent activity in the welfare program.\"# reuse earlier output\n",
    "\n",
    "# --- Step 2: Risk score (from previous module) ---\n",
    "risk_output = final_risk_score(suspicious_case)\n",
    "\n",
    "# --- Step 3: Audit summary ---\n",
    "audit_report = generate_audit_summary(\n",
    "    suspicious_case,\n",
    "    risk_output,\n",
    "    explanation_text\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ§¾ FINAL AUDIT REPORT\\n\")\n",
    "print(audit_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44350e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea6dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d7d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
